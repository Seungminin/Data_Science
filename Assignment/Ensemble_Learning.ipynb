{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from scipy.stats import mode\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      " 4   class              150 non-null    int32  \n",
      "dtypes: float64(4), int32(1)\n",
      "memory usage: 5.4 KB\n",
      "\n",
      " None\n",
      "\n",
      "      sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "145                6.7               3.0                5.2               2.3   \n",
      "146                6.3               2.5                5.0               1.9   \n",
      "147                6.5               3.0                5.2               2.0   \n",
      "148                6.2               3.4                5.4               2.3   \n",
      "149                5.9               3.0                5.1               1.8   \n",
      "\n",
      "     class  \n",
      "145      2  \n",
      "146      2  \n",
      "147      2  \n",
      "148      2  \n",
      "149      2  \n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['class'] = iris.target \n",
    "print(df['class'].unique()) #CLass are [0,1,2] 3 classes 0 : Versicolor, 1 : Setosa, 2 : Virginica \n",
    "print(\"\\n\",df.info()) #sample is 150 entries, feature 4 data, and target 1 data.\n",
    "print(\"\\n\",df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Allow duplication of bagging 10 times to pull out data and make 20 samples. \n",
    "#A total of 200 data are created and data that have never been pulled out are stored in Out of data\n",
    "def Bagging(dataset):\n",
    "    bagging_df = pd.DataFrame(columns=dataset.columns)\n",
    "    test_df = pd.DataFrame(columns=dataset.columns)\n",
    "    Out_of_Data = set(range(dataset.shape[0])) #Initial 200 sample(0~199), not duplication \n",
    "\n",
    "    training_index = pd.DataFrame() #save bootstraped index.\n",
    "\n",
    "    #generate 10 bagging dataset and each with 20 records.\n",
    "    for i in range(10):\n",
    "        data_index = list(range(150)) \n",
    "        random_data_index = np.random.choice(data_index, 20, replace=True) #restoration extraction\n",
    "        training_index[f'{i}th'] = random_data_index\n",
    "        bagging_sample = dataset.iloc[random_data_index, :]\n",
    "        bagging_df = pd.concat([bagging_df, bagging_sample], axis=0) #Stored in bagging_df via pulled data indices\n",
    "        Out_of_Data -= set(random_data_index) #remove the sampled data index\n",
    "    \n",
    "    Out_of_Data = list(Out_of_Data)\n",
    "    test_df = dataset.iloc[Out_of_Data, :]\n",
    "    print(\"\\n Not sampled data index : \",Out_of_Data, \"\\n Not sampled data length is : \",len(Out_of_Data))\n",
    "    print(\"\\nThe bootstrap training dataset index\\n\", training_index)\n",
    "    return bagging_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Not sampled data index :  [3, 4, 12, 16, 17, 18, 19, 21, 23, 24, 28, 45, 48, 55, 57, 70, 79, 81, 84, 86, 90, 92, 95, 103, 109, 113, 116, 117, 118, 122, 126, 131, 133, 137, 140, 141, 149] \n",
      " Not sampled data length is :  37\n",
      "\n",
      "The bootstrap training dataset index\n",
      "     0th  1th  2th  3th  4th  5th  6th  7th  8th  9th\n",
      "0    31  132  111  111  102   49   51    0   74   94\n",
      "1   146   96  124   62   74   47   76   67   40   53\n",
      "2   111   74   36   67   52  132   80   20   87  123\n",
      "3     0   75   68   30  130   98   72  129   78  110\n",
      "4    15    8  136   22   91    5  144   54  102   67\n",
      "5   135   10   42   82  135  145  128  119   63  124\n",
      "6    13  121   46  128   80   69   82   26  142   15\n",
      "7    65  123   85   88   85  104  145    1  125   44\n",
      "8     0  112  134   49  114  136  132   78   97   31\n",
      "9    43   93   98  139   35   13   35  120  106  112\n",
      "10   47    6   32   40    7    9   14   27  145   75\n",
      "11   68   59  145   73   67   50   53   41   49  105\n",
      "12   63   99   39   25   93   69   71   96   34    8\n",
      "13  138   99   74   10   50   41   80    2    8   96\n",
      "14   65   59   43   54   56  107  115   52   63   27\n",
      "15    2   96   32   63   78   47   46  127   47   38\n",
      "16   87  136   11   61   58   60   77   39   29  108\n",
      "17   89   65   62   31   41   64  107  114  101   33\n",
      "18  104   93  100  147   66   26   83   88   20   34\n",
      "19   46   93  143  120   82  144   37  148   35  107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksmin\\AppData\\Local\\Temp\\ipykernel_21268\\2636670353.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bagging_df = pd.concat([bagging_df, bagging_sample], axis=0) #Stored in bagging_df via pulled data indices\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#How to create #testdataset: Find the index as an intersection that has never been selected in the process of creating 10 bootstraps.\n",
    "bagging_df, test_df = Bagging(df)\n",
    "\n",
    "X_train = bagging_df.iloc[:,0:4].values\n",
    "y_train = bagging_df.iloc[:,-1].values\n",
    "\n",
    "X_test = test_df.iloc[:,0:4].values\n",
    "y_test = test_df.iloc[:,-1].values\n",
    "\n",
    "y_train = y_train.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.4 3.4 1.5 0.4]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.  2.2 4.  1. ]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [6.7 3.  5.  1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [6.  2.2 5.  1.5]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [7.3 2.9 6.3 1.8]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 2 0 0 2 0 1 0 0 0 1 1 2 1 0 1 1 2 0 2 1 1 1 0 0 2 2 2 1 0 1 1 1 1 1 2\n",
      " 1 1 1 2 2 0 1 2 0 0 1 2 1 0 2 0 1 0 0 0 1 2 2 2 1 1 0 0 1 2 1 0 2 0 1 0 0\n",
      " 1 1 1 0 2 2 2 1 1 2 1 2 1 1 2 0 0 1 1 1 1 1 1 0 1 1 0 0 2 1 0 2 1 2 2 0 0\n",
      " 1 1 0 2 0 1 1 0 2 1 1 1 1 2 2 1 2 2 0 0 1 1 1 2 0 1 2 1 0 0 1 0 2 1 2 0 0\n",
      " 1 2 0 0 1 0 1 2 0 2 1 2 1 0 1 1 2 1 2 2 1 2 2 0 0 0 1 0 0 2 0 0 1 1 2 2 1\n",
      " 2 0 0 0 2 1 2 0 1 0 0 2 0 0 2] \n",
      " y_train length is :  200\n",
      "\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2] \n",
      " y_test length is :  37\n"
     ]
    }
   ],
   "source": [
    "print(y_train, \"\\n y_train length is : \", len(y_train))\n",
    "print(\"\\n\", y_test, \"\\n y_test length is : \", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_CF(X_train,X_test,y_train,y_test):\n",
    "    #initialize 10 base learner model. and each base learners prediction about X_test\n",
    "    bagging_models = []\n",
    "    base_learner_predictions = np.zeros((X_test.shape[0],10))\n",
    "\n",
    "    #Run 10 (training) bagging rounds with BaggingClassifier function.\n",
    "    for i in range(10):\n",
    "        X = []\n",
    "        y= []\n",
    "        bagging_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=1, bootstrap=False)\n",
    "        X = X_train[(20*i):(20*i+20)]\n",
    "        y = y_train[(20*i):(20*i+20)]\n",
    "\n",
    "        bagging_clf.fit(X, y)\n",
    "        bagging_models.append(bagging_clf)\n",
    "\n",
    "    #each 10 base learners predict X_test(not sampled)\n",
    "    for i, model in enumerate(bagging_models):\n",
    "        base_learner_predictions[:,i] = model.estimators_[0].predict(X_test)\n",
    "    \n",
    "    # Perform majority voting (mode[0] : Most frequently repeated values, mode[1] : Repeated frequency)\n",
    "    majority_vote_predictions, _ = mode(base_learner_predictions, axis=1)\n",
    "    majority_vote_predictions = majority_vote_predictions.flatten()\n",
    "\n",
    "    y_pred = majority_vote_predictions\n",
    "\n",
    "    #accuracy score between real data and majority voted data = ensembled data\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    #Show a table (dataframe) with predictions from the 10 base learners and the final ensemble learner\n",
    "    predictions_df = pd.DataFrame(base_learner_predictions, columns=[f'{i+1}' for i in range(10)])\n",
    "\n",
    "    predictions_df['Ensemble'] = majority_vote_predictions\n",
    "    predictions_df[\"Reality\"] = y_test\n",
    "\n",
    "    confusion_matrix = Confuse_Matrix(predictions_df['Reality'],predictions_df['Ensemble'])\n",
    "    return predictions_df,confusion_matrix\n",
    "\n",
    "#Show the confusion matrix\n",
    "def Confuse_Matrix(reality, ensemble):\n",
    "    confusion_matrix = pd.crosstab(reality,ensemble,rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972972972972973\n",
      "      1    2    3    4    5    6    7    8    9   10  Ensemble  Reality\n",
      "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0        0\n",
      "1   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0        0\n",
      "2   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0        0\n",
      "3   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0        0\n",
      "4   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0        0\n",
      "5   0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0       0.0        0\n",
      "6   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0        0\n",
      "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0        0\n",
      "8   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0        0\n",
      "9   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0        0\n",
      "10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0        0\n",
      "11  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0        0\n",
      "12  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0        0\n",
      "13  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0       1.0        1\n",
      "14  1.0  1.0  1.0  0.0  1.0  1.0  1.0  0.0  1.0  1.0       1.0        1\n",
      "15  2.0  2.0  1.0  2.0  1.0  2.0  1.0  2.0  2.0  2.0       2.0        1\n",
      "16  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0       1.0        1\n",
      "17  1.0  1.0  1.0  0.0  1.0  1.0  1.0  0.0  1.0  1.0       1.0        1\n",
      "18  1.0  1.0  1.0  0.0  1.0  1.0  1.0  0.0  1.0  1.0       1.0        1\n",
      "19  1.0  2.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  2.0       1.0        1\n",
      "20  1.0  1.0  1.0  0.0  1.0  1.0  1.0  0.0  1.0  1.0       1.0        1\n",
      "21  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0       1.0        1\n",
      "22  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0       1.0        1\n",
      "23  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0       2.0        2\n",
      "24  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0       2.0        2\n",
      "25  2.0  2.0  2.0  2.0  1.0  2.0  1.0  2.0  2.0  2.0       2.0        2\n",
      "26  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0       2.0        2\n",
      "27  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0       2.0        2\n",
      "28  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0       2.0        2\n",
      "29  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0       2.0        2\n",
      "30  2.0  2.0  1.0  2.0  1.0  2.0  1.0  2.0  2.0  2.0       2.0        2\n",
      "31  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0       2.0        2\n",
      "32  2.0  2.0  2.0  1.0  2.0  1.0  1.0  2.0  1.0  2.0       2.0        2\n",
      "33  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0       2.0        2\n",
      "34  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0       2.0        2\n",
      "35  2.0  2.0  2.0  2.0  2.0  2.0  1.0  2.0  2.0  2.0       2.0        2\n",
      "36  2.0  2.0  2.0  2.0  2.0  2.0  1.0  2.0  2.0  2.0       2.0        2\n"
     ]
    }
   ],
   "source": [
    "predictions_df,confusion_matrix = bagging_CF(X_train,X_test,y_train,y_test)\n",
    "\n",
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  0.0  1.0  2.0\n",
      "Actual                  \n",
      "0           13    0    0\n",
      "1            0    9    1\n",
      "2            0    0   14\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
