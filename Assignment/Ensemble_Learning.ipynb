{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from scipy.stats import mode\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      " 4   class              150 non-null    int32  \n",
      "dtypes: float64(4), int32(1)\n",
      "memory usage: 5.4 KB\n",
      "\n",
      " None\n",
      "\n",
      "      sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "145                6.7               3.0                5.2               2.3   \n",
      "146                6.3               2.5                5.0               1.9   \n",
      "147                6.5               3.0                5.2               2.0   \n",
      "148                6.2               3.4                5.4               2.3   \n",
      "149                5.9               3.0                5.1               1.8   \n",
      "\n",
      "     class  \n",
      "145      2  \n",
      "146      2  \n",
      "147      2  \n",
      "148      2  \n",
      "149      2  \n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['class'] = iris.target \n",
    "print(df['class'].unique()) #CLass are [0,1,2] 3 classes 0 : Versicolor, 1 : Setosa, 2 : Virginica \n",
    "print(\"\\n\",df.info()) #sample is 150 entries, feature 4 data, and target 1 data.\n",
    "print(\"\\n\",df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Allow duplication of bagging 10 times to pull out data and make 20 samples. \n",
    "#A total of 200 data are created and data that have never been pulled out are stored in Out of data\n",
    "def Bagging(dataset):\n",
    "    bagging_df = pd.DataFrame(columns=dataset.columns)\n",
    "    test_df = pd.DataFrame(columns=dataset.columns)\n",
    "    Out_of_Data = set(range(dataset.shape[0])) #Initial 200 sample(0~199), not duplication \n",
    "\n",
    "    training_index = pd.DataFrame() #save bootstraped index.\n",
    "\n",
    "    #generate 10 bagging dataset and each with 20 records.\n",
    "    for i in range(10):\n",
    "        data_index = list(range(150)) \n",
    "        random_data_index = np.random.choice(data_index, 20, replace=True) #restoration extraction\n",
    "        training_index[f'{i}th'] = random_data_index\n",
    "        bagging_sample = dataset.iloc[random_data_index, :]\n",
    "        bagging_df = pd.concat([bagging_df, bagging_sample], axis=0) #Stored in bagging_df via pulled data indices\n",
    "        Out_of_Data -= set(random_data_index) #remove the sampled data index\n",
    "    \n",
    "    Out_of_Data = list(Out_of_Data)\n",
    "    test_df = dataset.iloc[Out_of_Data, :]\n",
    "    print(\"\\n Not sampled data index : \",Out_of_Data, \"\\n Not sampled data length is : \",len(Out_of_Data))\n",
    "    print(\"\\nThe bootstrap training dataset index\\n\", training_index)\n",
    "    return bagging_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Not sampled data index :  [3, 7, 16, 20, 28, 30, 31, 33, 39, 41, 46, 47, 50, 51, 65, 70, 73, 74, 75, 83, 85, 89, 93, 95, 99, 102, 103, 111, 113, 114, 120, 121, 134, 137, 139, 143, 144, 147] \n",
      " Not sampled data length is :  38\n",
      "\n",
      "The bootstrap training dataset index\n",
      "     0th  1th  2th  3th  4th  5th  6th  7th  8th  9th\n",
      "0    36  128   69  108  149  124   64   11   66   18\n",
      "1    91  127   57  115   17  117   94   59   82  125\n",
      "2    53   32   62   21   14   63    1  128   98  129\n",
      "3   118   98   87   96    0    9   24   48    2  105\n",
      "4    64  122  106    9   64   45  131    1   43  112\n",
      "5    72   68   79   11   40   97  141   36   19   80\n",
      "6    92    6  110   63   80   67  107    5   43  146\n",
      "7    15   34   34  132  125   27   54   79   84   17\n",
      "8    49  140  142   61  119   35   94  118  115  124\n",
      "9    97  146   18  142   24   59  141   42   94   57\n",
      "10  100   68  125  145  136  106  104  109  142  116\n",
      "11   35   15  136   26  141   58  148   60   57   22\n",
      "12   90   42  130   96  146   37   53   55   90   24\n",
      "13  140  118  133  135   69   17   82   96   29   78\n",
      "14  123   88   32   63  129    9  109   78   80  126\n",
      "15   55  126   61   59   57   17  149    0  105   32\n",
      "16   24   38   44   63   49  130   12   86   56  131\n",
      "17   59   77    6  132   10   94  100    9   25  136\n",
      "18   67   43  128    8   72   76   42   88   13   52\n",
      "19   38   24  140  109   71   81    4  138  101   23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksmin\\AppData\\Local\\Temp\\ipykernel_21268\\2636670353.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bagging_df = pd.concat([bagging_df, bagging_sample], axis=0) #Stored in bagging_df via pulled data indices\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#How to create #testdataset: Find the index as an intersection that has never been selected in the process of creating 10 bootstraps.\n",
    "bagging_df, test_df = Bagging(df)\n",
    "\n",
    "X_train = bagging_df.iloc[:,0:4].values\n",
    "y_train = bagging_df.iloc[:,-1].values\n",
    "\n",
    "X_test = test_df.iloc[:,0:4].values\n",
    "y_test = test_df.iloc[:,-1].values\n",
    "\n",
    "y_train = y_train.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.5 3.5 1.3 0.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [6.7 3.  5.  1.7]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.  2.2 5.  1.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [6.  3.  4.8 1.8]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [5.  3.  1.6 0.2]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.1 3.3 1.7 0.5]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 2 1 1 1 0 0 1 2 0 1 2 2 1 0 1 1 0 2 2 0 1 2 1 0 0 2 2 1 0 0 2 1 2 0\n",
      " 1 0 0 1 1 1 1 2 1 2 0 2 0 2 2 2 2 0 1 0 0 2 2 2 2 0 1 0 0 1 2 1 2 2 0 1 2\n",
      " 1 1 1 2 0 2 2 0 0 0 1 0 1 2 2 0 2 2 2 1 2 1 0 0 1 1 2 2 1 0 0 1 1 0 0 1 2\n",
      " 1 0 0 0 0 2 1 1 1 1 1 0 0 2 2 2 1 1 2 2 2 1 1 2 2 0 2 0 0 0 1 2 0 0 0 0 1\n",
      " 2 0 2 1 1 1 1 0 1 0 1 2 1 1 1 0 0 0 0 1 2 1 2 1 1 0 1 2 1 0 0 2 0 2 2 2 2\n",
      " 1 2 0 2 1 2 0 0 1 2 0 2 2 1 0] \n",
      " y_train length is :  200\n",
      "\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2] \n",
      " y_test length is :  38\n"
     ]
    }
   ],
   "source": [
    "print(y_train, \"\\n y_train length is : \", len(y_train))\n",
    "print(\"\\n\", y_test, \"\\n y_test length is : \", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_CF(X_train,X_test,y_train,y_test):\n",
    "    bagging_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), \n",
    "    n_estimators=10,\n",
    "    bootstrap=True,\n",
    "    random_state=42\n",
    "    )\n",
    "    bagging_clf.fit(X_train,y_train)\n",
    "\n",
    "    #initialize each base learners prediction\n",
    "    base_learner_predictions = np.zeros((X_test.shape[0],10))\n",
    "\n",
    "    for i, estimator in enumerate(bagging_clf.estimators_):\n",
    "        base_learner_predictions[:,i] = estimator.predict(X_test)\n",
    "    \n",
    "    # Perform majority voting (mode[0] : Most frequently repeated values, mode[1] : Repeated frequency)\n",
    "    majority_vote_predictions, _ = mode(base_learner_predictions, axis=1)\n",
    "    majority_vote_predictions = majority_vote_predictions.flatten()\n",
    "\n",
    "    y_pred = bagging_clf.predict(X_test)\n",
    "\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    predictions_df = pd.DataFrame(base_learner_predictions, columns=[f'{i+1}' for i in range(10)])\n",
    "\n",
    "    predictions_df['Ensemble'] = y_pred\n",
    "    predictions_df['Vote'] = majority_vote_predictions\n",
    "    predictions_df[\"Reality\"] = y_test\n",
    "\n",
    "    confusion_matrix = Confuse_Matrix(predictions_df['Reality'],predictions_df['Ensemble'])\n",
    "    return predictions_df,confusion_matrix\n",
    "\n",
    "def Confuse_Matrix(reality, ensemble):\n",
    "    confusion_matrix = pd.crosstab(reality,ensemble,rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9473684210526315\n",
      "      1    2    3    4    5    6    7    8    9   10  Ensemble  Vote  Reality\n",
      "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0   0.0        0\n",
      "1   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0   0.0        0\n",
      "2   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0   0.0        0\n",
      "3   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0   0.0        0\n",
      "4   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0   0.0        0\n",
      "5   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0   0.0        0\n",
      "6   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0   0.0        0\n",
      "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0   0.0        0\n",
      "8   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0   0.0        0\n",
      "9   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0   0.0        0\n",
      "10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0   0.0        0\n",
      "11  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0   0.0        0\n",
      "12  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0         1   1.0        1\n",
      "13  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0         1   1.0        1\n",
      "14  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0         1   1.0        1\n",
      "15  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0         2   2.0        1\n",
      "16  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0         1   1.0        1\n",
      "17  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0         1   1.0        1\n",
      "18  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0         1   1.0        1\n",
      "19  2.0  2.0  2.0  2.0  1.0  2.0  1.0  2.0  2.0  2.0         2   2.0        1\n",
      "20  1.0  1.0  1.0  1.0  1.0  1.0  1.0  2.0  1.0  1.0         1   1.0        1\n",
      "21  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0         1   1.0        1\n",
      "22  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0         1   1.0        1\n",
      "23  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0         1   1.0        1\n",
      "24  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0         1   1.0        1\n",
      "25  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0         2   2.0        2\n",
      "26  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0         2   2.0        2\n",
      "27  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0         2   2.0        2\n",
      "28  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0         2   2.0        2\n",
      "29  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0         2   2.0        2\n",
      "30  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0         2   2.0        2\n",
      "31  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0         2   2.0        2\n",
      "32  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0         2   2.0        2\n",
      "33  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0         2   2.0        2\n",
      "34  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0         2   2.0        2\n",
      "35  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0         2   2.0        2\n",
      "36  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0         2   2.0        2\n",
      "37  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0         2   2.0        2\n"
     ]
    }
   ],
   "source": [
    "predictions_df,confusion_matrix = bagging_CF(X_train,X_test,y_train,y_test)\n",
    "\n",
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   0   1   2\n",
      "Actual               \n",
      "0          12   0   0\n",
      "1           0  11   2\n",
      "2           0   0  13\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
